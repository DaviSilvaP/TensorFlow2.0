{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.24.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.5.4)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.19.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.0.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f30b404c358>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01 \n",
    "comms_round = 100\n",
    "loss='categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "optimizer = tf.keras.optimizers.SGD(lr=lr, decay= lr/comms_round, momentum=0.9)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clients = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_indexes(X, n_clients):\n",
    "    indexes = np.arange(np.random.randint(int(X.shape[0] * 0.8), X.shape[0]))\n",
    "    \n",
    "    np.random.shuffle(indexes)\n",
    "    indexes = np.array_split(indexes, n_clients)\n",
    "    \n",
    "    clients_index = np.arange(n_clients)\n",
    "    np.random.shuffle(clients_index)\n",
    "    \n",
    "    half_clients = int(n_clients / 2)\n",
    "    samples = np.random.random_sample((half_clients,))\n",
    "    for i in range(half_clients):\n",
    "        client_A = indexes[clients_index[i]]\n",
    "        client_B = indexes[clients_index[i + half_clients]]\n",
    "        \n",
    "        client_A = np.concatenate((client_A, client_B[:int(client_B.shape[0] * samples[i])]))\n",
    "        client_B = client_B[int(client_B.shape[0] * samples[i]):]\n",
    "        \n",
    "        indexes[clients_index[i]] = client_A\n",
    "        indexes[clients_index[i + half_clients]] = client_B\n",
    "    \n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clients(X, y, n_clients):\n",
    "\n",
    "    indexes = generate_indexes(X, n_clients)\n",
    "    \n",
    "    X_slices = np.array([X[indexes[i]] for i in range(n_clients)], dtype='object')\n",
    "    y_slices = np.array([y[indexes[i]] for i in range(n_clients)], dtype='object')\n",
    "    return X_slices, y_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def build(self):\n",
    "        model = tf.keras.models.Sequential()\n",
    "        model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=[32,32,3]))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "        model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "        model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dropout(0.2))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation='tanh'))\n",
    "        model.add(tf.keras.layers.Dropout(0.2))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dropout(0.2))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation='tanh'))\n",
    "        model.add(tf.keras.layers.Dropout(0.2))\n",
    "        model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_update(local_data, global_data, model):    \n",
    "    weights = (local_data / global_data) * np.array(client_model.get_weights(), dtype='object')\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 2.0853 - accuracy: 0.2452\n",
      "Round 0, Loss: 2.084, Accuracy: 0.240\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4875 - accuracy: 0.4565\n",
      "Round 1, Loss: 1.488, Accuracy: 0.456\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3264 - accuracy: 0.5172\n",
      "Round 2, Loss: 1.326, Accuracy: 0.517\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.2128 - accuracy: 0.5609\n",
      "Round 3, Loss: 1.213, Accuracy: 0.561\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.1040 - accuracy: 0.6097\n",
      "Round 4, Loss: 1.104, Accuracy: 0.610\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.0396 - accuracy: 0.6357\n",
      "Round 5, Loss: 1.040, Accuracy: 0.636\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.9795 - accuracy: 0.6635\n",
      "Round 6, Loss: 0.979, Accuracy: 0.664\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.9405 - accuracy: 0.6791\n",
      "Round 7, Loss: 0.941, Accuracy: 0.679\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.9092 - accuracy: 0.6906\n",
      "Round 8, Loss: 0.909, Accuracy: 0.691\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.8872 - accuracy: 0.7049\n",
      "Round 9, Loss: 0.887, Accuracy: 0.705\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.8916 - accuracy: 0.7094\n",
      "Round 10, Loss: 0.892, Accuracy: 0.709\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.8920 - accuracy: 0.7114\n",
      "Round 11, Loss: 0.892, Accuracy: 0.711\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.8983 - accuracy: 0.7157\n",
      "Round 12, Loss: 0.898, Accuracy: 0.716\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.8900 - accuracy: 0.7183\n",
      "Round 13, Loss: 0.890, Accuracy: 0.718\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.9020 - accuracy: 0.7205\n",
      "Round 14, Loss: 0.902, Accuracy: 0.720\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.9209 - accuracy: 0.7215\n",
      "Round 15, Loss: 0.921, Accuracy: 0.721\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.9561 - accuracy: 0.7178\n",
      "Round 16, Loss: 0.956, Accuracy: 0.718\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.9612 - accuracy: 0.7219\n",
      "Round 17, Loss: 0.961, Accuracy: 0.722\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.9717 - accuracy: 0.7231\n",
      "Round 18, Loss: 0.972, Accuracy: 0.723\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.9963 - accuracy: 0.7237\n",
      "Round 19, Loss: 0.996, Accuracy: 0.724\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.9979 - accuracy: 0.7270\n",
      "Round 20, Loss: 0.998, Accuracy: 0.727\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.0208 - accuracy: 0.7240\n",
      "Round 21, Loss: 1.021, Accuracy: 0.724\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.0429 - accuracy: 0.7216\n",
      "Round 22, Loss: 1.043, Accuracy: 0.722\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.0866 - accuracy: 0.7186\n",
      "Round 23, Loss: 1.087, Accuracy: 0.719\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.1021 - accuracy: 0.7243\n",
      "Round 24, Loss: 1.102, Accuracy: 0.724\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.0680 - accuracy: 0.7243\n",
      "Round 25, Loss: 1.068, Accuracy: 0.724\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.1207 - accuracy: 0.7209\n",
      "Round 26, Loss: 1.121, Accuracy: 0.721\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.1239 - accuracy: 0.7225\n",
      "Round 27, Loss: 1.124, Accuracy: 0.723\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.1513 - accuracy: 0.7239\n",
      "Round 28, Loss: 1.151, Accuracy: 0.724\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.1807 - accuracy: 0.7203\n",
      "Round 29, Loss: 1.181, Accuracy: 0.720\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.1732 - accuracy: 0.7222\n",
      "Round 30, Loss: 1.173, Accuracy: 0.722\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.1996 - accuracy: 0.7241\n",
      "Round 31, Loss: 1.200, Accuracy: 0.724\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.2220 - accuracy: 0.7234\n",
      "Round 32, Loss: 1.222, Accuracy: 0.723\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.2456 - accuracy: 0.7211\n",
      "Round 33, Loss: 1.246, Accuracy: 0.721\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.2567 - accuracy: 0.7216\n",
      "Round 34, Loss: 1.257, Accuracy: 0.722\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.2202 - accuracy: 0.7203\n",
      "Round 35, Loss: 1.220, Accuracy: 0.720\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.2468 - accuracy: 0.7220\n",
      "Round 36, Loss: 1.247, Accuracy: 0.722\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.2647 - accuracy: 0.7225\n",
      "Round 37, Loss: 1.265, Accuracy: 0.723\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.2923 - accuracy: 0.7245\n",
      "Round 38, Loss: 1.292, Accuracy: 0.725\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.2812 - accuracy: 0.7213\n",
      "Round 39, Loss: 1.281, Accuracy: 0.721\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.2741 - accuracy: 0.7221\n",
      "Round 40, Loss: 1.274, Accuracy: 0.722\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.2982 - accuracy: 0.7241\n",
      "Round 41, Loss: 1.298, Accuracy: 0.724\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3339 - accuracy: 0.7213\n",
      "Round 42, Loss: 1.334, Accuracy: 0.721\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3502 - accuracy: 0.7217\n",
      "Round 43, Loss: 1.350, Accuracy: 0.722\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3591 - accuracy: 0.7208\n",
      "Round 44, Loss: 1.359, Accuracy: 0.721\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3628 - accuracy: 0.7246\n",
      "Round 45, Loss: 1.363, Accuracy: 0.725\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3841 - accuracy: 0.7227\n",
      "Round 46, Loss: 1.384, Accuracy: 0.723\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3641 - accuracy: 0.7227\n",
      "Round 47, Loss: 1.364, Accuracy: 0.723\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3891 - accuracy: 0.7223\n",
      "Round 48, Loss: 1.389, Accuracy: 0.722\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4122 - accuracy: 0.7234\n",
      "Round 49, Loss: 1.412, Accuracy: 0.723\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4138 - accuracy: 0.7233\n",
      "Round 50, Loss: 1.414, Accuracy: 0.723\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4004 - accuracy: 0.7232\n",
      "Round 51, Loss: 1.400, Accuracy: 0.723\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4171 - accuracy: 0.7266\n",
      "Round 52, Loss: 1.417, Accuracy: 0.727\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4111 - accuracy: 0.7205\n",
      "Round 53, Loss: 1.411, Accuracy: 0.720\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4339 - accuracy: 0.7206\n",
      "Round 54, Loss: 1.434, Accuracy: 0.721\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4428 - accuracy: 0.7236\n",
      "Round 55, Loss: 1.443, Accuracy: 0.724\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4604 - accuracy: 0.7230\n",
      "Round 56, Loss: 1.460, Accuracy: 0.723\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4664 - accuracy: 0.7217\n",
      "Round 57, Loss: 1.466, Accuracy: 0.722\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4699 - accuracy: 0.7259\n",
      "Round 58, Loss: 1.470, Accuracy: 0.726\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4790 - accuracy: 0.7258\n",
      "Round 59, Loss: 1.479, Accuracy: 0.726\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4869 - accuracy: 0.7226\n",
      "Round 60, Loss: 1.487, Accuracy: 0.723\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4860 - accuracy: 0.7220\n",
      "Round 61, Loss: 1.486, Accuracy: 0.722\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4860 - accuracy: 0.7196\n",
      "Round 62, Loss: 1.486, Accuracy: 0.720\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4967 - accuracy: 0.7228\n",
      "Round 63, Loss: 1.497, Accuracy: 0.723\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4685 - accuracy: 0.7236\n",
      "Round 64, Loss: 1.468, Accuracy: 0.724\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4859 - accuracy: 0.7228\n",
      "Round 65, Loss: 1.486, Accuracy: 0.723\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4807 - accuracy: 0.7236\n",
      "Round 66, Loss: 1.481, Accuracy: 0.724\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4997 - accuracy: 0.7216\n",
      "Round 67, Loss: 1.500, Accuracy: 0.722\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5049 - accuracy: 0.7225\n",
      "Round 68, Loss: 1.505, Accuracy: 0.723\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5103 - accuracy: 0.7198\n",
      "Round 69, Loss: 1.510, Accuracy: 0.720\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5251 - accuracy: 0.7246\n",
      "Round 70, Loss: 1.525, Accuracy: 0.725\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5271 - accuracy: 0.7253\n",
      "Round 71, Loss: 1.527, Accuracy: 0.725\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5305 - accuracy: 0.7258\n",
      "Round 72, Loss: 1.531, Accuracy: 0.726\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5158 - accuracy: 0.7264\n",
      "Round 73, Loss: 1.516, Accuracy: 0.726\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5307 - accuracy: 0.7260\n",
      "Round 74, Loss: 1.531, Accuracy: 0.726\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5317 - accuracy: 0.7229\n",
      "Round 75, Loss: 1.532, Accuracy: 0.723\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5352 - accuracy: 0.7240\n",
      "Round 76, Loss: 1.535, Accuracy: 0.724\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5219 - accuracy: 0.7229\n",
      "Round 77, Loss: 1.522, Accuracy: 0.723\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5355 - accuracy: 0.7248\n",
      "Round 78, Loss: 1.535, Accuracy: 0.725\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5443 - accuracy: 0.7241\n",
      "Round 79, Loss: 1.544, Accuracy: 0.724\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5558 - accuracy: 0.7220\n",
      "Round 80, Loss: 1.556, Accuracy: 0.722\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5537 - accuracy: 0.7234\n",
      "Round 81, Loss: 1.554, Accuracy: 0.723\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5552 - accuracy: 0.7242\n",
      "Round 82, Loss: 1.555, Accuracy: 0.724\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5629 - accuracy: 0.7239\n",
      "Round 83, Loss: 1.563, Accuracy: 0.724\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5662 - accuracy: 0.7241\n",
      "Round 84, Loss: 1.566, Accuracy: 0.724\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5677 - accuracy: 0.7268\n",
      "Round 85, Loss: 1.568, Accuracy: 0.727\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5659 - accuracy: 0.7256\n",
      "Round 86, Loss: 1.566, Accuracy: 0.726\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5813 - accuracy: 0.7255\n",
      "Round 87, Loss: 1.581, Accuracy: 0.725\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5883 - accuracy: 0.7236\n",
      "Round 88, Loss: 1.588, Accuracy: 0.724\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5984 - accuracy: 0.7203\n",
      "Round 89, Loss: 1.598, Accuracy: 0.720\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5806 - accuracy: 0.7245\n",
      "Round 90, Loss: 1.581, Accuracy: 0.725\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5932 - accuracy: 0.7210\n",
      "Round 91, Loss: 1.593, Accuracy: 0.721\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5865 - accuracy: 0.7233\n",
      "Round 92, Loss: 1.586, Accuracy: 0.723\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5995 - accuracy: 0.7214\n",
      "Round 93, Loss: 1.600, Accuracy: 0.721\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5939 - accuracy: 0.7238\n",
      "Round 94, Loss: 1.594, Accuracy: 0.724\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5928 - accuracy: 0.7260\n",
      "Round 95, Loss: 1.593, Accuracy: 0.726\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6033 - accuracy: 0.7251\n",
      "Round 96, Loss: 1.603, Accuracy: 0.725\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6099 - accuracy: 0.7231\n",
      "Round 97, Loss: 1.610, Accuracy: 0.723\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6137 - accuracy: 0.7263\n",
      "Round 98, Loss: 1.614, Accuracy: 0.726\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6130 - accuracy: 0.7245\n",
      "Round 99, Loss: 1.613, Accuracy: 0.725\n"
     ]
    }
   ],
   "source": [
    "mlp = CNN()\n",
    "\n",
    "global_model = mlp.build()\n",
    "global_model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "for j in range(comms_round):\n",
    "\n",
    "    global_weights = global_model.get_weights()\n",
    "    new_global_weights = [np.zeros(weight.shape) for weight in global_weights]\n",
    "    \n",
    "    X_slices, y_slices = create_clients(X_train, y_train, n_clients)\n",
    "    global_data = sum([size.shape[0] for size in X_slices])\n",
    "    \n",
    "    for i in range(n_clients):\n",
    "        client_model = mlp.build()\n",
    "        client_model.compile(loss=loss, \n",
    "                      optimizer=optimizer, \n",
    "                      metrics=metrics)\n",
    "        \n",
    "        client_model.set_weights(global_weights)\n",
    "        client_model.fit(X_slices[i], y_slices[i], epochs=2, verbose=0)\n",
    "        \n",
    "        weights = NN_update(X_slices[i].shape[0], global_data, client_model)\n",
    "        \n",
    "        new_global_weights += np.array(weights, dtype='object')\n",
    "    \n",
    "    global_model.set_weights(new_global_weights)\n",
    "    \n",
    "    test_loss, test_accuracy = global_model.evaluate(X_test, y_test)\n",
    "    print(\"Round {}, Loss: {:.3f}, Accuracy: {:.3f}\".format(j, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
