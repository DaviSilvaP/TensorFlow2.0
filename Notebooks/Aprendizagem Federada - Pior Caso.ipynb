{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.24.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.19.4)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.5.4)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f31980459b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
       " array([5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01 \n",
    "comms_round = 100\n",
    "loss='categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "optimizer = tf.keras.optimizers.SGD(lr=lr, decay= lr/comms_round, momentum=0.9)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clients = np.unique(y_train).shape[0] // 2 # 5\n",
    "lb = LabelBinarizer()\n",
    "y_test = lb.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clients(X, y, n_clients):\n",
    "\n",
    "    indexes = [np.where((y_train == x) | (y_train == x+1))[0] for x in range(0,10,2)]\n",
    "    y = lb.fit_transform(y_train) \n",
    "    \n",
    "    X_slices = np.array([X[indexes[i]] for i in range(n_clients)], dtype='object').astype('float32')\n",
    "    y_slices = np.array([y[indexes[i]] for i in range(n_clients)], dtype='object').astype('float32')\n",
    "    return X_slices, y_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def build(self):\n",
    "        model = tf.keras.models.Sequential()\n",
    "        model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=[32,32,3]))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "        model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "        model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dropout(0.2))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation='tanh'))\n",
    "        model.add(tf.keras.layers.Dropout(0.2))\n",
    "        model.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dropout(0.2))\n",
    "        model.add(tf.keras.layers.Dense(units=32, activation='tanh'))\n",
    "        model.add(tf.keras.layers.Dropout(0.2))\n",
    "        model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_update(local_data, global_data, model):    \n",
    "    weights = (local_data / global_data) * np.array(model.get_weights(), dtype='object')\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 2.7168 - accuracy: 0.1002\n",
      "Round 0, Loss: 2.703, Accuracy: 0.100\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 3.4824 - accuracy: 0.1004\n",
      "Round 1, Loss: 3.482, Accuracy: 0.100\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.8451 - accuracy: 0.0997\n",
      "Round 2, Loss: 2.845, Accuracy: 0.100\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.5580 - accuracy: 0.1204\n",
      "Round 3, Loss: 2.558, Accuracy: 0.120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.5247 - accuracy: 0.1137\n",
      "Round 4, Loss: 2.525, Accuracy: 0.114\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 3.0610 - accuracy: 0.1029\n",
      "Round 5, Loss: 3.061, Accuracy: 0.103\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.6289 - accuracy: 0.1634\n",
      "Round 6, Loss: 2.629, Accuracy: 0.163\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.5697 - accuracy: 0.1232\n",
      "Round 7, Loss: 2.570, Accuracy: 0.123\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.3927 - accuracy: 0.1662\n",
      "Round 8, Loss: 2.393, Accuracy: 0.166\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.3613 - accuracy: 0.1408\n",
      "Round 9, Loss: 2.361, Accuracy: 0.141\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.3012 - accuracy: 0.2170\n",
      "Round 10, Loss: 2.301, Accuracy: 0.217\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.4525 - accuracy: 0.2056\n",
      "Round 11, Loss: 2.452, Accuracy: 0.206\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.4668 - accuracy: 0.2135\n",
      "Round 12, Loss: 2.467, Accuracy: 0.213\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.2743 - accuracy: 0.2187\n",
      "Round 13, Loss: 2.274, Accuracy: 0.219\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.6302 - accuracy: 0.1648\n",
      "Round 14, Loss: 2.630, Accuracy: 0.165\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.2537 - accuracy: 0.2540\n",
      "Round 15, Loss: 2.254, Accuracy: 0.254\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.6892 - accuracy: 0.1499\n",
      "Round 16, Loss: 2.689, Accuracy: 0.150\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.2793 - accuracy: 0.2693\n",
      "Round 17, Loss: 2.279, Accuracy: 0.269\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.1884 - accuracy: 0.2385\n",
      "Round 18, Loss: 2.188, Accuracy: 0.238\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.1201 - accuracy: 0.2745\n",
      "Round 19, Loss: 2.120, Accuracy: 0.275\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.2794 - accuracy: 0.2383\n",
      "Round 20, Loss: 2.279, Accuracy: 0.238\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.1395 - accuracy: 0.2660\n",
      "Round 21, Loss: 2.139, Accuracy: 0.266\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.3565 - accuracy: 0.2576\n",
      "Round 22, Loss: 2.357, Accuracy: 0.258\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.1966 - accuracy: 0.2492\n",
      "Round 23, Loss: 2.197, Accuracy: 0.249\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.1952 - accuracy: 0.2668\n",
      "Round 24, Loss: 2.195, Accuracy: 0.267\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.9819 - accuracy: 0.3056\n",
      "Round 25, Loss: 1.982, Accuracy: 0.306\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.3044 - accuracy: 0.2425\n",
      "Round 26, Loss: 2.304, Accuracy: 0.243\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.1229 - accuracy: 0.3468\n",
      "Round 27, Loss: 2.123, Accuracy: 0.347\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.1219 - accuracy: 0.2629\n",
      "Round 28, Loss: 2.122, Accuracy: 0.263\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.0810 - accuracy: 0.3530\n",
      "Round 29, Loss: 2.081, Accuracy: 0.353\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.8979 - accuracy: 0.3234\n",
      "Round 30, Loss: 1.898, Accuracy: 0.323\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.9557 - accuracy: 0.3622\n",
      "Round 31, Loss: 1.956, Accuracy: 0.362\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.1212 - accuracy: 0.3097\n",
      "Round 32, Loss: 2.121, Accuracy: 0.310\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.0063 - accuracy: 0.3672\n",
      "Round 33, Loss: 2.006, Accuracy: 0.367\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.9588 - accuracy: 0.3316\n",
      "Round 34, Loss: 1.959, Accuracy: 0.332\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.8613 - accuracy: 0.3810\n",
      "Round 35, Loss: 1.861, Accuracy: 0.381\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.8223 - accuracy: 0.3651\n",
      "Round 36, Loss: 1.822, Accuracy: 0.365\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.8182 - accuracy: 0.3918\n",
      "Round 37, Loss: 1.818, Accuracy: 0.392\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.7260 - accuracy: 0.3949\n",
      "Round 38, Loss: 1.726, Accuracy: 0.395\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.7442 - accuracy: 0.4172\n",
      "Round 39, Loss: 1.744, Accuracy: 0.417\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6977 - accuracy: 0.4142\n",
      "Round 40, Loss: 1.698, Accuracy: 0.414\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6975 - accuracy: 0.4239\n",
      "Round 41, Loss: 1.697, Accuracy: 0.424\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6756 - accuracy: 0.4289\n",
      "Round 42, Loss: 1.676, Accuracy: 0.429\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6954 - accuracy: 0.4303\n",
      "Round 43, Loss: 1.695, Accuracy: 0.430\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6758 - accuracy: 0.4270\n",
      "Round 44, Loss: 1.676, Accuracy: 0.427\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6691 - accuracy: 0.4369\n",
      "Round 45, Loss: 1.669, Accuracy: 0.437\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6771 - accuracy: 0.4348\n",
      "Round 46, Loss: 1.677, Accuracy: 0.435\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6631 - accuracy: 0.4422\n",
      "Round 47, Loss: 1.663, Accuracy: 0.442\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6494 - accuracy: 0.4434\n",
      "Round 48, Loss: 1.649, Accuracy: 0.443\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6471 - accuracy: 0.4460\n",
      "Round 49, Loss: 1.647, Accuracy: 0.446\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6364 - accuracy: 0.4509\n",
      "Round 50, Loss: 1.636, Accuracy: 0.451\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6550 - accuracy: 0.4498\n",
      "Round 51, Loss: 1.655, Accuracy: 0.450\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6396 - accuracy: 0.4543\n",
      "Round 52, Loss: 1.640, Accuracy: 0.454\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6499 - accuracy: 0.4578\n",
      "Round 53, Loss: 1.650, Accuracy: 0.458\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6252 - accuracy: 0.4593\n",
      "Round 54, Loss: 1.625, Accuracy: 0.459\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6412 - accuracy: 0.4585\n",
      "Round 55, Loss: 1.641, Accuracy: 0.458\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6405 - accuracy: 0.4565\n",
      "Round 56, Loss: 1.641, Accuracy: 0.456\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6355 - accuracy: 0.4616\n",
      "Round 57, Loss: 1.636, Accuracy: 0.462\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6131 - accuracy: 0.4661\n",
      "Round 58, Loss: 1.613, Accuracy: 0.466\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6183 - accuracy: 0.4686\n",
      "Round 59, Loss: 1.618, Accuracy: 0.469\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6068 - accuracy: 0.4736\n",
      "Round 60, Loss: 1.607, Accuracy: 0.474\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6116 - accuracy: 0.4696\n",
      "Round 61, Loss: 1.612, Accuracy: 0.470\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6149 - accuracy: 0.4760\n",
      "Round 62, Loss: 1.615, Accuracy: 0.476\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6258 - accuracy: 0.4721\n",
      "Round 63, Loss: 1.626, Accuracy: 0.472\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6032 - accuracy: 0.4814\n",
      "Round 64, Loss: 1.603, Accuracy: 0.481\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6132 - accuracy: 0.4740\n",
      "Round 65, Loss: 1.613, Accuracy: 0.474\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6094 - accuracy: 0.4806\n",
      "Round 66, Loss: 1.609, Accuracy: 0.481\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6159 - accuracy: 0.4792\n",
      "Round 67, Loss: 1.616, Accuracy: 0.479\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6089 - accuracy: 0.4843\n",
      "Round 68, Loss: 1.609, Accuracy: 0.484\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6378 - accuracy: 0.4765\n",
      "Round 69, Loss: 1.638, Accuracy: 0.477\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6179 - accuracy: 0.4827\n",
      "Round 70, Loss: 1.618, Accuracy: 0.483\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6301 - accuracy: 0.4806\n",
      "Round 71, Loss: 1.630, Accuracy: 0.481\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6106 - accuracy: 0.4853\n",
      "Round 72, Loss: 1.611, Accuracy: 0.485\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6035 - accuracy: 0.4845\n",
      "Round 73, Loss: 1.604, Accuracy: 0.484\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6220 - accuracy: 0.4845\n",
      "Round 74, Loss: 1.622, Accuracy: 0.484\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6103 - accuracy: 0.4862\n",
      "Round 75, Loss: 1.610, Accuracy: 0.486\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6144 - accuracy: 0.4861\n",
      "Round 76, Loss: 1.614, Accuracy: 0.486\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6135 - accuracy: 0.4879\n",
      "Round 77, Loss: 1.614, Accuracy: 0.488\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6059 - accuracy: 0.4858\n",
      "Round 78, Loss: 1.606, Accuracy: 0.486\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6174 - accuracy: 0.4907\n",
      "Round 79, Loss: 1.617, Accuracy: 0.491\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6168 - accuracy: 0.4890\n",
      "Round 80, Loss: 1.617, Accuracy: 0.489\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6322 - accuracy: 0.4914\n",
      "Round 81, Loss: 1.632, Accuracy: 0.491\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6219 - accuracy: 0.4918\n",
      "Round 82, Loss: 1.622, Accuracy: 0.492\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6180 - accuracy: 0.4916\n",
      "Round 83, Loss: 1.618, Accuracy: 0.492\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6414 - accuracy: 0.4863\n",
      "Round 84, Loss: 1.641, Accuracy: 0.486\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6251 - accuracy: 0.4919\n",
      "Round 85, Loss: 1.625, Accuracy: 0.492\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6320 - accuracy: 0.4935\n",
      "Round 86, Loss: 1.632, Accuracy: 0.493\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6218 - accuracy: 0.4964\n",
      "Round 87, Loss: 1.622, Accuracy: 0.496\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6277 - accuracy: 0.4923\n",
      "Round 88, Loss: 1.628, Accuracy: 0.492\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6258 - accuracy: 0.4990\n",
      "Round 89, Loss: 1.626, Accuracy: 0.499\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6377 - accuracy: 0.4951\n",
      "Round 90, Loss: 1.638, Accuracy: 0.495\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6337 - accuracy: 0.4999\n",
      "Round 91, Loss: 1.634, Accuracy: 0.500\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6435 - accuracy: 0.4953\n",
      "Round 92, Loss: 1.643, Accuracy: 0.495\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6408 - accuracy: 0.5004\n",
      "Round 93, Loss: 1.641, Accuracy: 0.500\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6379 - accuracy: 0.4989\n",
      "Round 94, Loss: 1.638, Accuracy: 0.499\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6296 - accuracy: 0.5026\n",
      "Round 95, Loss: 1.630, Accuracy: 0.503\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6397 - accuracy: 0.5049\n",
      "Round 96, Loss: 1.640, Accuracy: 0.505\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6274 - accuracy: 0.5078\n",
      "Round 97, Loss: 1.627, Accuracy: 0.508\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6535 - accuracy: 0.5022\n",
      "Round 98, Loss: 1.653, Accuracy: 0.502\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6421 - accuracy: 0.5042\n",
      "Round 99, Loss: 1.642, Accuracy: 0.504\n"
     ]
    }
   ],
   "source": [
    "mlp = CNN()\n",
    "\n",
    "global_model = mlp.build()\n",
    "global_model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "X_slices, y_slices = create_clients(X_train, y_train, n_clients)\n",
    "\n",
    "for j in range(comms_round):\n",
    "\n",
    "    global_weights = global_model.get_weights()\n",
    "    new_global_weights = [np.zeros(weight.shape) for weight in global_weights]\n",
    "    \n",
    "    global_data = sum([size.shape[0] for size in X_slices])\n",
    "    \n",
    "    for i in range(n_clients):\n",
    "        client_model = mlp.build()\n",
    "        client_model.compile(loss=loss, \n",
    "                      optimizer=optimizer, \n",
    "                      metrics=metrics)\n",
    "        \n",
    "        client_model.set_weights(global_weights)\n",
    "        client_model.fit(X_slices[i], y_slices[i], epochs=2, verbose=0)\n",
    "        \n",
    "        weights = NN_update(X_slices[i].shape[0], global_data, client_model)\n",
    "        \n",
    "        new_global_weights += np.array(weights, dtype='object')\n",
    "    \n",
    "    global_model.set_weights(new_global_weights)\n",
    "    \n",
    "    test_loss, test_accuracy = global_model.evaluate(X_test, y_test)\n",
    "    print(\"Round {}, Loss: {:.3f}, Accuracy: {:.3f}\".format(j, test_loss, test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
